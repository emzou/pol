{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/emilyzou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk \n",
    "import string \n",
    "nltk.download('punkt')\n",
    "from statistics import median\n",
    "from statistics import mean\n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"11_6_fulldataset.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## categorizing quoted by \n",
    "def process_quotes(s):\n",
    "    if \"Quoted By\" in s: \n",
    "        return re.findall(r'>>(\\d+)\\n', s)\n",
    "    else:\n",
    "        modified_string = s  # no modification needed if \"Quoted By\" is not present\n",
    "        return \"No Quote\"\n",
    "\n",
    "df['quotedby'] = df['Identifier'].apply(process_quotes)\n",
    "\n",
    "## removing it from the text \n",
    "\n",
    "def stripper (s): \n",
    "    if 'Quoted By' in s:\n",
    "        cleaned_string = re.sub(r'Quoted By:|>>\\d+\\n', '', s)\n",
    "        return cleaned_string.strip()\n",
    "    else: \n",
    "        return s\n",
    "\n",
    "df ['Text'] = df['Text'].apply(stripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the reply-to out \n",
    "\n",
    "df['replyto'] = df['Text'].apply(lambda text: re.findall(r'>>(\\d+)', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(lambda text: re.sub(r'>>\\d+\\s*', '', text).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip website links from the text\n",
    "# it means 'image of god' in latin \n",
    "sitepattern = r'(?:https?://|www\\.)\\S+|[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,6}(?:/[^\\s]*)?'\n",
    "df['Text'] = df['Text'].apply(lambda text: re.sub(sitepattern, '', text).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip 'imago dei' comments from the text\n",
    "df = df[~df['Text'].str.contains('imago', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Text'].str.contains('amplissimus', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Text'].str.contains('amplissimus', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's so much more latin than i thought \n",
    "# lingua-py (https://github.com/pemistahl/lingua-py)\n",
    "languages = [Language.LATIN, Language.ENGLISH]\n",
    "detector = LanguageDetectorBuilder.from_languages(*languages).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latin_exterminator(s):\n",
    "    confidence_value = detector.compute_language_confidence(s, Language.LATIN)\n",
    "    cv = float(f\"{confidence_value:.2f}\") \n",
    "    if cv >= 0.5:\n",
    "        return None\n",
    "    else: \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the latin exterminator\n",
    "df['Text'] = df['Text'].apply(latin_exterminator)\n",
    "df = df[df['Text'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Text</th>\n",
       "      <th>anonid</th>\n",
       "      <th>date</th>\n",
       "      <th>number</th>\n",
       "      <th>quotedby</th>\n",
       "      <th>replyto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>:RqQXr/xt Sat 01 Oct 2022 13:20:28 No.397859125</td>\n",
       "      <td>Tumblr girls were the nerdy outcasts who went ...</td>\n",
       "      <td>:RqQXr/xt</td>\n",
       "      <td>Sat 01 Oct 2022 13:20:28</td>\n",
       "      <td>397859125</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>:+XF1CsQm Sat 01 Oct 2022 12:41:09 No.397853920</td>\n",
       "      <td>what is the topic, then?\\nYou're like the nigg...</td>\n",
       "      <td>:+XF1CsQm</td>\n",
       "      <td>Sat 01 Oct 2022 12:41:09</td>\n",
       "      <td>397853920</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[397853706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>:Ytn2j+6s Sat 01 Oct 2022 10:01:18 No.397834023</td>\n",
       "      <td>Lots of anons posting ITT about “making it” in...</td>\n",
       "      <td>:Ytn2j+6s</td>\n",
       "      <td>Sat 01 Oct 2022 10:01:18</td>\n",
       "      <td>397834023</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[397814529]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>:O8h7xH1H Sun 02 Oct 2022 16:31:37 No.39803282...</td>\n",
       "      <td>These are the three pillars of the US and west...</td>\n",
       "      <td>:O8h7xH1H</td>\n",
       "      <td>Sun 02 Oct 2022 16:31:37</td>\n",
       "      <td>398032820</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>:JsLtzO4W Sun 02 Oct 2022 11:32:05 No.397991514</td>\n",
       "      <td>Haha, indeed. The DEI mind virus has infected ...</td>\n",
       "      <td>:JsLtzO4W</td>\n",
       "      <td>Sun 02 Oct 2022 11:32:05</td>\n",
       "      <td>397991514</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[397984711]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70803</th>\n",
       "      <td>:kecsvdvI Wed 30 Oct 2024 22:14:55 No.48646562...</td>\n",
       "      <td>THE CAN BARELY GASLIGHT THIS WITHIN THEIR OWN ...</td>\n",
       "      <td>:kecsvdvI</td>\n",
       "      <td>Wed 30 Oct 2024 22:14:55</td>\n",
       "      <td>486465624</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70804</th>\n",
       "      <td>:EF5Mz2zI Wed 30 Oct 2024 22:02:24 No.48646490...</td>\n",
       "      <td>Here's my objective assessment of Stephen Mill...</td>\n",
       "      <td>:EF5Mz2zI</td>\n",
       "      <td>Wed 30 Oct 2024 22:02:24</td>\n",
       "      <td>486464907</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70805</th>\n",
       "      <td>:cUMz4T2R Wed 30 Oct 2024 21:55:11 No.48646451...</td>\n",
       "      <td>There are a bunch of reasons. There are many f...</td>\n",
       "      <td>:cUMz4T2R</td>\n",
       "      <td>Wed 30 Oct 2024 21:55:11</td>\n",
       "      <td>486464519</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70806</th>\n",
       "      <td>:0egXPX4Z Wed 30 Oct 2024 21:34:59 No.48646320...</td>\n",
       "      <td>&gt;But what does this mean?\\nDEI, troons, wars, ...</td>\n",
       "      <td>:0egXPX4Z</td>\n",
       "      <td>Wed 30 Oct 2024 21:34:59</td>\n",
       "      <td>486463202</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70807</th>\n",
       "      <td>:jjadV5KJ Wed 30 Oct 2024 21:07:51 No.48646135...</td>\n",
       "      <td>If you want an example of an actual good Jew t...</td>\n",
       "      <td>:jjadV5KJ</td>\n",
       "      <td>Wed 30 Oct 2024 21:07:51</td>\n",
       "      <td>486461353</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32570 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Identifier  \\\n",
       "16       :RqQXr/xt Sat 01 Oct 2022 13:20:28 No.397859125   \n",
       "17       :+XF1CsQm Sat 01 Oct 2022 12:41:09 No.397853920   \n",
       "19       :Ytn2j+6s Sat 01 Oct 2022 10:01:18 No.397834023   \n",
       "31     :O8h7xH1H Sun 02 Oct 2022 16:31:37 No.39803282...   \n",
       "33       :JsLtzO4W Sun 02 Oct 2022 11:32:05 No.397991514   \n",
       "...                                                  ...   \n",
       "70803  :kecsvdvI Wed 30 Oct 2024 22:14:55 No.48646562...   \n",
       "70804  :EF5Mz2zI Wed 30 Oct 2024 22:02:24 No.48646490...   \n",
       "70805  :cUMz4T2R Wed 30 Oct 2024 21:55:11 No.48646451...   \n",
       "70806  :0egXPX4Z Wed 30 Oct 2024 21:34:59 No.48646320...   \n",
       "70807  :jjadV5KJ Wed 30 Oct 2024 21:07:51 No.48646135...   \n",
       "\n",
       "                                                    Text     anonid  \\\n",
       "16     Tumblr girls were the nerdy outcasts who went ...  :RqQXr/xt   \n",
       "17     what is the topic, then?\\nYou're like the nigg...  :+XF1CsQm   \n",
       "19     Lots of anons posting ITT about “making it” in...  :Ytn2j+6s   \n",
       "31     These are the three pillars of the US and west...  :O8h7xH1H   \n",
       "33     Haha, indeed. The DEI mind virus has infected ...  :JsLtzO4W   \n",
       "...                                                  ...        ...   \n",
       "70803  THE CAN BARELY GASLIGHT THIS WITHIN THEIR OWN ...  :kecsvdvI   \n",
       "70804  Here's my objective assessment of Stephen Mill...  :EF5Mz2zI   \n",
       "70805  There are a bunch of reasons. There are many f...  :cUMz4T2R   \n",
       "70806  >But what does this mean?\\nDEI, troons, wars, ...  :0egXPX4Z   \n",
       "70807  If you want an example of an actual good Jew t...  :jjadV5KJ   \n",
       "\n",
       "                           date     number  quotedby      replyto  \n",
       "16     Sat 01 Oct 2022 13:20:28  397859125  No Quote           []  \n",
       "17     Sat 01 Oct 2022 12:41:09  397853920  No Quote  [397853706]  \n",
       "19     Sat 01 Oct 2022 10:01:18  397834023  No Quote  [397814529]  \n",
       "31     Sun 02 Oct 2022 16:31:37  398032820  No Quote           []  \n",
       "33     Sun 02 Oct 2022 11:32:05  397991514  No Quote  [397984711]  \n",
       "...                         ...        ...       ...          ...  \n",
       "70803  Wed 30 Oct 2024 22:14:55  486465624  No Quote           []  \n",
       "70804  Wed 30 Oct 2024 22:02:24  486464907  No Quote           []  \n",
       "70805  Wed 30 Oct 2024 21:55:11  486464519  No Quote           []  \n",
       "70806  Wed 30 Oct 2024 21:34:59  486463202  No Quote           []  \n",
       "70807  Wed 30 Oct 2024 21:07:51  486461353  No Quote           []  \n",
       "\n",
       "[32570 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates by anon-id (this only refers to the post, not the account)\n",
    "df = df.drop_duplicates(subset = 'anonid', keep = 'last')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/j4cr1qk10pgfhhshk13f4zgm0000gn/T/ipykernel_14813/3938567432.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Text_Sent'] = df['Text'].apply(sentsplit)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Text</th>\n",
       "      <th>anonid</th>\n",
       "      <th>date</th>\n",
       "      <th>number</th>\n",
       "      <th>quotedby</th>\n",
       "      <th>replyto</th>\n",
       "      <th>Text_Sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>:RqQXr/xt Sat 01 Oct 2022 13:20:28 No.397859125</td>\n",
       "      <td>Tumblr girls were the nerdy outcasts who went ...</td>\n",
       "      <td>:RqQXr/xt</td>\n",
       "      <td>Sat 01 Oct 2022 13:20:28</td>\n",
       "      <td>397859125</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Tumblr girls were the nerdy outcasts who went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>:+XF1CsQm Sat 01 Oct 2022 12:41:09 No.397853920</td>\n",
       "      <td>what is the topic, then?\\nYou're like the nigg...</td>\n",
       "      <td>:+XF1CsQm</td>\n",
       "      <td>Sat 01 Oct 2022 12:41:09</td>\n",
       "      <td>397853920</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[397853706]</td>\n",
       "      <td>[what is the topic, then?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>:Ytn2j+6s Sat 01 Oct 2022 10:01:18 No.397834023</td>\n",
       "      <td>Lots of anons posting ITT about “making it” in...</td>\n",
       "      <td>:Ytn2j+6s</td>\n",
       "      <td>Sat 01 Oct 2022 10:01:18</td>\n",
       "      <td>397834023</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[397814529]</td>\n",
       "      <td>[Lots of anons posting ITT about “making it” i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>:O8h7xH1H Sun 02 Oct 2022 16:31:37 No.39803282...</td>\n",
       "      <td>These are the three pillars of the US and west...</td>\n",
       "      <td>:O8h7xH1H</td>\n",
       "      <td>Sun 02 Oct 2022 16:31:37</td>\n",
       "      <td>398032820</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[These are the three pillars of the US and wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>:JsLtzO4W Sun 02 Oct 2022 11:32:05 No.397991514</td>\n",
       "      <td>Haha, indeed. The DEI mind virus has infected ...</td>\n",
       "      <td>:JsLtzO4W</td>\n",
       "      <td>Sun 02 Oct 2022 11:32:05</td>\n",
       "      <td>397991514</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[397984711]</td>\n",
       "      <td>[Haha, indeed., The DEI mind virus has infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70803</th>\n",
       "      <td>:kecsvdvI Wed 30 Oct 2024 22:14:55 No.48646562...</td>\n",
       "      <td>THE CAN BARELY GASLIGHT THIS WITHIN THEIR OWN ...</td>\n",
       "      <td>:kecsvdvI</td>\n",
       "      <td>Wed 30 Oct 2024 22:14:55</td>\n",
       "      <td>486465624</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70804</th>\n",
       "      <td>:EF5Mz2zI Wed 30 Oct 2024 22:02:24 No.48646490...</td>\n",
       "      <td>Here's my objective assessment of Stephen Mill...</td>\n",
       "      <td>:EF5Mz2zI</td>\n",
       "      <td>Wed 30 Oct 2024 22:02:24</td>\n",
       "      <td>486464907</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Here's my objective assessment of Stephen Mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70805</th>\n",
       "      <td>:cUMz4T2R Wed 30 Oct 2024 21:55:11 No.48646451...</td>\n",
       "      <td>There are a bunch of reasons. There are many f...</td>\n",
       "      <td>:cUMz4T2R</td>\n",
       "      <td>Wed 30 Oct 2024 21:55:11</td>\n",
       "      <td>486464519</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[There are a bunch of reasons., There are many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70806</th>\n",
       "      <td>:0egXPX4Z Wed 30 Oct 2024 21:34:59 No.48646320...</td>\n",
       "      <td>&gt;But what does this mean?\\nDEI, troons, wars, ...</td>\n",
       "      <td>:0egXPX4Z</td>\n",
       "      <td>Wed 30 Oct 2024 21:34:59</td>\n",
       "      <td>486463202</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&gt;But what does this mean?, DEI, troons, wars,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70807</th>\n",
       "      <td>:jjadV5KJ Wed 30 Oct 2024 21:07:51 No.48646135...</td>\n",
       "      <td>If you want an example of an actual good Jew t...</td>\n",
       "      <td>:jjadV5KJ</td>\n",
       "      <td>Wed 30 Oct 2024 21:07:51</td>\n",
       "      <td>486461353</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[If you want an example of an actual good Jew ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Identifier  \\\n",
       "16       :RqQXr/xt Sat 01 Oct 2022 13:20:28 No.397859125   \n",
       "17       :+XF1CsQm Sat 01 Oct 2022 12:41:09 No.397853920   \n",
       "19       :Ytn2j+6s Sat 01 Oct 2022 10:01:18 No.397834023   \n",
       "31     :O8h7xH1H Sun 02 Oct 2022 16:31:37 No.39803282...   \n",
       "33       :JsLtzO4W Sun 02 Oct 2022 11:32:05 No.397991514   \n",
       "...                                                  ...   \n",
       "70803  :kecsvdvI Wed 30 Oct 2024 22:14:55 No.48646562...   \n",
       "70804  :EF5Mz2zI Wed 30 Oct 2024 22:02:24 No.48646490...   \n",
       "70805  :cUMz4T2R Wed 30 Oct 2024 21:55:11 No.48646451...   \n",
       "70806  :0egXPX4Z Wed 30 Oct 2024 21:34:59 No.48646320...   \n",
       "70807  :jjadV5KJ Wed 30 Oct 2024 21:07:51 No.48646135...   \n",
       "\n",
       "                                                    Text     anonid  \\\n",
       "16     Tumblr girls were the nerdy outcasts who went ...  :RqQXr/xt   \n",
       "17     what is the topic, then?\\nYou're like the nigg...  :+XF1CsQm   \n",
       "19     Lots of anons posting ITT about “making it” in...  :Ytn2j+6s   \n",
       "31     These are the three pillars of the US and west...  :O8h7xH1H   \n",
       "33     Haha, indeed. The DEI mind virus has infected ...  :JsLtzO4W   \n",
       "...                                                  ...        ...   \n",
       "70803  THE CAN BARELY GASLIGHT THIS WITHIN THEIR OWN ...  :kecsvdvI   \n",
       "70804  Here's my objective assessment of Stephen Mill...  :EF5Mz2zI   \n",
       "70805  There are a bunch of reasons. There are many f...  :cUMz4T2R   \n",
       "70806  >But what does this mean?\\nDEI, troons, wars, ...  :0egXPX4Z   \n",
       "70807  If you want an example of an actual good Jew t...  :jjadV5KJ   \n",
       "\n",
       "                           date     number  quotedby      replyto  \\\n",
       "16     Sat 01 Oct 2022 13:20:28  397859125  No Quote           []   \n",
       "17     Sat 01 Oct 2022 12:41:09  397853920  No Quote  [397853706]   \n",
       "19     Sat 01 Oct 2022 10:01:18  397834023  No Quote  [397814529]   \n",
       "31     Sun 02 Oct 2022 16:31:37  398032820  No Quote           []   \n",
       "33     Sun 02 Oct 2022 11:32:05  397991514  No Quote  [397984711]   \n",
       "...                         ...        ...       ...          ...   \n",
       "70803  Wed 30 Oct 2024 22:14:55  486465624  No Quote           []   \n",
       "70804  Wed 30 Oct 2024 22:02:24  486464907  No Quote           []   \n",
       "70805  Wed 30 Oct 2024 21:55:11  486464519  No Quote           []   \n",
       "70806  Wed 30 Oct 2024 21:34:59  486463202  No Quote           []   \n",
       "70807  Wed 30 Oct 2024 21:07:51  486461353  No Quote           []   \n",
       "\n",
       "                                               Text_Sent  \n",
       "16     [Tumblr girls were the nerdy outcasts who went...  \n",
       "17                            [what is the topic, then?]  \n",
       "19     [Lots of anons posting ITT about “making it” i...  \n",
       "31     [These are the three pillars of the US and wes...  \n",
       "33     [Haha, indeed., The DEI mind virus has infecte...  \n",
       "...                                                  ...  \n",
       "70803                                                 []  \n",
       "70804  [Here's my objective assessment of Stephen Mil...  \n",
       "70805  [There are a bunch of reasons., There are many...  \n",
       "70806  [>But what does this mean?, DEI, troons, wars,...  \n",
       "70807  [If you want an example of an actual good Jew ...  \n",
       "\n",
       "[32570 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence detection based on punctuation\n",
    "# convert string into list of strings, separated by sentences\n",
    "\n",
    "def sentsplit (text):\n",
    "    pattern = r'[^.!?]*[.!?]'\n",
    "    sentences = [sentence.strip() for sentence in re.findall(pattern, text)]\n",
    "    return sentences \n",
    "\n",
    "df['Text_Sent'] = df['Text'].apply(sentsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m         sentences\u001b[39m.\u001b[39mappend([sent\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39msents])\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m sentences\n\u001b[0;32m----> 8\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mSent\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mText\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(detect_sentences_spacy)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/series.py:4753\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4754\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4755\u001b[0m         func,\n\u001b[1;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4758\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m   4760\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1289\u001b[0m )\n\u001b[1;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn [18], line 4\u001b[0m, in \u001b[0;36mdetect_sentences_spacy\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect_sentences_spacy\u001b[39m(text):\n\u001b[1;32m      3\u001b[0m     sentences \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m nlp\u001b[39m.\u001b[39mpipe(text, disable\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mner\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mparser\u001b[39m\u001b[39m\"\u001b[39m]):  \u001b[39m# go dude go\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         sentences\u001b[39m.\u001b[39mappend([sent\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39msents])\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m sentences\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/language.py:1618\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[1;32m   1616\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[1;32m   1617\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n\u001b[0;32m-> 1618\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[1;32m   1619\u001b[0m     \u001b[39myield\u001b[39;00m doc\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/util.py:1685\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1676\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1677\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1683\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1684\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1685\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1686\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1687\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/pipeline/pipe.pyx:55\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/util.py:1685\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1676\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1677\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1683\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1684\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1685\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1686\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1687\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/pipeline/pipe.pyx:55\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/util.py:1685\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1676\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1677\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1683\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1684\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1685\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1686\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1687\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/util.py:1632\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m   1631\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[0;32m-> 1632\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(items, \u001b[39mint\u001b[39;49m(batch_size)))\n\u001b[1;32m   1633\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1634\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/util.py:1685\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1676\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1677\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1683\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1684\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1685\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1686\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1687\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:75\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_dim(\u001b[39m\"\u001b[39m\u001b[39mnO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39malloc((\u001b[39m0\u001b[39m, width)) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(docs)\n\u001b[1;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/layers/with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     41\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/layers/with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     75\u001b[0m lengths \u001b[39m=\u001b[39m NUMPY_OPS\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[1;32m     76\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[0;32m---> 77\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[1;32m     80\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/thinc/layers/maxout.py:52\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     50\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_param(\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape2f(W, nO \u001b[39m*\u001b[39m nP, nI)\n\u001b[0;32m---> 52\u001b[0m Y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mgemm(X, W, trans2\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     53\u001b[0m Y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape1f(b, nO \u001b[39m*\u001b[39m nP)\n\u001b[1;32m     54\u001b[0m Z \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape3f(Y, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nO, nP)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sentence detection validation with spacy... ugh, this is too slow\n",
    "def detect_sentences_spacy(text):\n",
    "    sentences = []\n",
    "    for doc in nlp.pipe(text, disable=[\"ner\", \"parser\"]):  # go dude go\n",
    "        sentences.append([sent.text.strip() for sent in doc.sents])\n",
    "    return sentences\n",
    "\n",
    "df['Sent'] = df['Text'].apply(detect_sentences_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the differences between manual and spacy sentence split \n",
    "def you_a_mismatch(row):\n",
    "    mismatches = sum(1 for m, s in zip(row['Text_Sent'], row['Sent']) if m != s)\n",
    "    mismatches += abs(len(row['Text_Sent']) - len(row['Text_Sent']))\n",
    "    return mismatches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for len > 512 \n",
    "# identify 'dei' position \n",
    "# trim non-dei sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/j4cr1qk10pgfhhshk13f4zgm0000gn/T/ipykernel_11976/1510224106.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['Text'].apply(nltk.word_tokenize)\n",
      "/var/folders/b9/j4cr1qk10pgfhhshk13f4zgm0000gn/T/ipykernel_11976/1510224106.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokenslower'] = df['tokens'].apply(cleanlower)\n",
      "/var/folders/b9/j4cr1qk10pgfhhshk13f4zgm0000gn/T/ipykernel_11976/1510224106.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tokens'] = df['tokenslower'].apply(fix_contractions)\n"
     ]
    }
   ],
   "source": [
    "#tokenizing \n",
    "df['tokens'] = df['Text'].apply(nltk.word_tokenize)\n",
    "\n",
    "\n",
    "def cleanlower (m): \n",
    "    return [s.lower() for s in m if s not in string.punctuation]\n",
    "\n",
    "df['tokenslower'] = df['tokens'].apply(cleanlower)\n",
    "\n",
    "def fix_contractions(tokens):\n",
    "    contraction_suffixes = [\"'t\", \"'m\", \"'ve\", \"'ll\", \"'d\", \"'re\", \"'s\", \"n't\"]\n",
    "    fixed_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i < len(tokens) - 1 and tokens[i + 1] in contraction_suffixes:\n",
    "            if tokens[i + 1] in [\"'t\", \"n't\"]:\n",
    "                fixed_tokens.append(tokens[i])  \n",
    "            else:\n",
    "                fixed_tokens.append(tokens[i] + tokens[i + 1])\n",
    "            i += 1\n",
    "        else:\n",
    "            fixed_tokens.append(tokens[i])\n",
    "        i += 1\n",
    "\n",
    "    return fixed_tokens\n",
    "\n",
    "df['Tokens'] = df['tokenslower'].apply(fix_contractions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_tokens(df, word, before, after):\n",
    "    mentions = [\n",
    "        (word, row['date'], \n",
    "         row['Tokens'][max(i - before, 0):i],  \n",
    "         row['Tokens'][i + 1:i + 1 + after],  \n",
    "         len(row['Tokens']))  \n",
    "        for _, row in df.iterrows()  \n",
    "        for i, token in enumerate(row['Tokens'])  \n",
    "        if token == word  # Match the specific word\n",
    "    ]\n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = capture_tokens(df, 'dei', 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dictionaries for before and after \n",
    "# this should be integrated with the above function later\n",
    "def abdict (m): \n",
    "    unilist_list = [x[m] for x in unigram]\n",
    "    uniflat = [x for l in unilist_list for x in l] #flatten the list poggers\n",
    "    unidict = dict(Counter(uniflat))\n",
    "    unidict1 = {k:v for k,v in unidict.items() if v >1} # change v depending on what we want to exclude \n",
    "    sortubdict = dict(sorted(unidict1.items(), key=lambda item: item[1], reverse = True))\n",
    "    return sortubdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abdict(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets test the hypothesis - lets see if theres any trend with 'hire' and 'hires' ... so NOUN NOUN \n",
    "# is 'dei hire' a bigram or is 'hire' interchangeable \n",
    "# which words are (significantly) semantically similar to 'hire' \n",
    "# do the above via cosine similarity (i think this already exists) #this is literally BERT lmao\n",
    "# if we find 'rules' for how to use a word, how predictable are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneword_datecheck(word):\n",
    "    return [m for m in unigram if word in m[3]]\n",
    "\n",
    "oneword_datecheck(\"hire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae82a169ccee4be4b581c6a81493610a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b5954588f3438c84f54ac85bb19b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717fac17e84940abb7ca15683c67429c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06378171d0f849faadc2769e8140c76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b3e0b7e1db4c84919ebfd06974b8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sequence = ['dei', 'hire']\n",
    "target_df = df[df['Tokens'].apply(lambda x: isinstance(x, list) and target_sequence in [x[i:i+2] for i in range(len(x)-1)])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_word_embeddings(tokens):\n",
    "    sentence = \" \".join(tokens)\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", is_split_into_words=False)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    \n",
    "    # get bert embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # get embeddings for each word\n",
    "    embeddings = outputs.last_hidden_state[0]\n",
    "    bert_tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "    # map tokens to embeddings\n",
    "    word_embeddings = {}\n",
    "    for i, token in enumerate(bert_tokens):\n",
    "        word_embeddings[token] = embeddings[i]\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Text</th>\n",
       "      <th>anonid</th>\n",
       "      <th>date</th>\n",
       "      <th>number</th>\n",
       "      <th>quotedby</th>\n",
       "      <th>replyto</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokenslower</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>:J2jVZ6MH Thu 22 Dec 2022 16:03:58 No.40932578...</td>\n",
       "      <td>&gt;patty flipper malfunctions\\n&gt;DEI hire with no...</td>\n",
       "      <td>:J2jVZ6MH</td>\n",
       "      <td>Thu 22 Dec 2022 16:03:58</td>\n",
       "      <td>409325789</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&gt;, patty, flipper, malfunctions, &gt;, DEI, hire...</td>\n",
       "      <td>[patty, flipper, malfunctions, dei, hire, with...</td>\n",
       "      <td>[patty, flipper, malfunctions, dei, hire, with...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>:325H1wYP Sun 22 Jan 2023 08:49:08 No.41318015...</td>\n",
       "      <td>he's a mi6 puke using a cia provided proxy for...</td>\n",
       "      <td>:325H1wYP</td>\n",
       "      <td>Sun 22 Jan 2023 08:49:08</td>\n",
       "      <td>413180151</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[he, 's, a, mi6, puke, using, a, cia, provided...</td>\n",
       "      <td>[he, 's, a, mi6, puke, using, a, cia, provided...</td>\n",
       "      <td>[he's, a, mi6, puke, using, a, cia, provided, ...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>:oJL5epR6 Wed 25 Jan 2023 17:13:59 No.41363654...</td>\n",
       "      <td>seems fake or he's DEI hire or pfizer has phis...</td>\n",
       "      <td>:oJL5epR6</td>\n",
       "      <td>Wed 25 Jan 2023 17:13:59</td>\n",
       "      <td>413636549</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seems, fake, or, he, 's, DEI, hire, or, pfize...</td>\n",
       "      <td>[seems, fake, or, he, 's, dei, hire, or, pfize...</td>\n",
       "      <td>[seems, fake, or, he's, dei, hire, or, pfizer,...</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>:TtfG5wdH Thu 26 Jan 2023 09:15:07 No.41371597...</td>\n",
       "      <td>Checked, this was Blizzard's new DEI hire a fe...</td>\n",
       "      <td>:TtfG5wdH</td>\n",
       "      <td>Thu 26 Jan 2023 09:15:07</td>\n",
       "      <td>413715974</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Checked, ,, this, was, Blizzard, 's, new, DEI...</td>\n",
       "      <td>[checked, this, was, blizzard, 's, new, dei, h...</td>\n",
       "      <td>[checked, this, was, blizzard's, new, dei, hir...</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>:edSUBszY Fri 27 Jan 2023 07:17:39 No.41383307...</td>\n",
       "      <td>all the traders know everything is fake - ever...</td>\n",
       "      <td>:edSUBszY</td>\n",
       "      <td>Fri 27 Jan 2023 07:17:39</td>\n",
       "      <td>413833079</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[all, the, traders, know, everything, is, fake...</td>\n",
       "      <td>[all, the, traders, know, everything, is, fake...</td>\n",
       "      <td>[all, the, traders, know, everything, is, fake...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70771</th>\n",
       "      <td>:e+yxuGgu Thu 31 Oct 2024 09:46:56 No.48650579...</td>\n",
       "      <td>Shill me why I should vote for your preferred ...</td>\n",
       "      <td>:e+yxuGgu</td>\n",
       "      <td>Thu 31 Oct 2024 09:46:56</td>\n",
       "      <td>486505795</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Shill, me, why, I, should, vote, for, your, p...</td>\n",
       "      <td>[shill, me, why, i, should, vote, for, your, p...</td>\n",
       "      <td>[shill, me, why, i, should, vote, for, your, p...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70781</th>\n",
       "      <td>:wxUiGawG Thu 31 Oct 2024 07:58:41 No.48649757...</td>\n",
       "      <td>VPN hohol detected\\nYou've got a point. Nobody...</td>\n",
       "      <td>:wxUiGawG</td>\n",
       "      <td>Thu 31 Oct 2024 07:58:41</td>\n",
       "      <td>486497574</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VPN, hohol, detected, You, 've, got, a, point...</td>\n",
       "      <td>[vpn, hohol, detected, you, 've, got, a, point...</td>\n",
       "      <td>[vpn, hohol, detected, you've, got, a, point, ...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70784</th>\n",
       "      <td>:OzpwjE85 Thu 31 Oct 2024 07:21:47 No.48649442...</td>\n",
       "      <td>She's a DEI hire, so no.\\n\\nPost\\nReport</td>\n",
       "      <td>:OzpwjE85</td>\n",
       "      <td>Thu 31 Oct 2024 07:21:47</td>\n",
       "      <td>486494427</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[She, 's, a, DEI, hire, ,, so, no, ., Post, Re...</td>\n",
       "      <td>[she, 's, a, dei, hire, so, no, post, report]</td>\n",
       "      <td>[she's, a, dei, hire, so, no, post, report]</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70795</th>\n",
       "      <td>:VM6RuOIN Thu 31 Oct 2024 02:42:22 No.48647845...</td>\n",
       "      <td>Being a low IQ DEI hire with an active vocabul...</td>\n",
       "      <td>:VM6RuOIN</td>\n",
       "      <td>Thu 31 Oct 2024 02:42:22</td>\n",
       "      <td>486478451</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Being, a, low, IQ, DEI, hire, with, an, activ...</td>\n",
       "      <td>[being, a, low, iq, dei, hire, with, an, activ...</td>\n",
       "      <td>[being, a, low, iq, dei, hire, with, an, activ...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70801</th>\n",
       "      <td>:xjZZ6riN Wed 30 Oct 2024 22:51:37 No.48646758...</td>\n",
       "      <td>Lol. Kamala is a DEI hire.\\n\\nPost\\nReport</td>\n",
       "      <td>:xjZZ6riN</td>\n",
       "      <td>Wed 30 Oct 2024 22:51:37</td>\n",
       "      <td>486467580</td>\n",
       "      <td>No Quote</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Lol, ., Kamala, is, a, DEI, hire, ., Post, Re...</td>\n",
       "      <td>[lol, kamala, is, a, dei, hire, post, report]</td>\n",
       "      <td>[lol, kamala, is, a, dei, hire, post, report]</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1551 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Identifier  \\\n",
       "1231   :J2jVZ6MH Thu 22 Dec 2022 16:03:58 No.40932578...   \n",
       "1617   :325H1wYP Sun 22 Jan 2023 08:49:08 No.41318015...   \n",
       "1715   :oJL5epR6 Wed 25 Jan 2023 17:13:59 No.41363654...   \n",
       "1774   :TtfG5wdH Thu 26 Jan 2023 09:15:07 No.41371597...   \n",
       "1808   :edSUBszY Fri 27 Jan 2023 07:17:39 No.41383307...   \n",
       "...                                                  ...   \n",
       "70771  :e+yxuGgu Thu 31 Oct 2024 09:46:56 No.48650579...   \n",
       "70781  :wxUiGawG Thu 31 Oct 2024 07:58:41 No.48649757...   \n",
       "70784  :OzpwjE85 Thu 31 Oct 2024 07:21:47 No.48649442...   \n",
       "70795  :VM6RuOIN Thu 31 Oct 2024 02:42:22 No.48647845...   \n",
       "70801  :xjZZ6riN Wed 30 Oct 2024 22:51:37 No.48646758...   \n",
       "\n",
       "                                                    Text     anonid  \\\n",
       "1231   >patty flipper malfunctions\\n>DEI hire with no...  :J2jVZ6MH   \n",
       "1617   he's a mi6 puke using a cia provided proxy for...  :325H1wYP   \n",
       "1715   seems fake or he's DEI hire or pfizer has phis...  :oJL5epR6   \n",
       "1774   Checked, this was Blizzard's new DEI hire a fe...  :TtfG5wdH   \n",
       "1808   all the traders know everything is fake - ever...  :edSUBszY   \n",
       "...                                                  ...        ...   \n",
       "70771  Shill me why I should vote for your preferred ...  :e+yxuGgu   \n",
       "70781  VPN hohol detected\\nYou've got a point. Nobody...  :wxUiGawG   \n",
       "70784           She's a DEI hire, so no.\\n\\nPost\\nReport  :OzpwjE85   \n",
       "70795  Being a low IQ DEI hire with an active vocabul...  :VM6RuOIN   \n",
       "70801         Lol. Kamala is a DEI hire.\\n\\nPost\\nReport  :xjZZ6riN   \n",
       "\n",
       "                           date     number  quotedby replyto  \\\n",
       "1231   Thu 22 Dec 2022 16:03:58  409325789  No Quote      []   \n",
       "1617   Sun 22 Jan 2023 08:49:08  413180151  No Quote      []   \n",
       "1715   Wed 25 Jan 2023 17:13:59  413636549  No Quote      []   \n",
       "1774   Thu 26 Jan 2023 09:15:07  413715974  No Quote      []   \n",
       "1808   Fri 27 Jan 2023 07:17:39  413833079  No Quote      []   \n",
       "...                         ...        ...       ...     ...   \n",
       "70771  Thu 31 Oct 2024 09:46:56  486505795  No Quote      []   \n",
       "70781  Thu 31 Oct 2024 07:58:41  486497574  No Quote      []   \n",
       "70784  Thu 31 Oct 2024 07:21:47  486494427  No Quote      []   \n",
       "70795  Thu 31 Oct 2024 02:42:22  486478451  No Quote      []   \n",
       "70801  Wed 30 Oct 2024 22:51:37  486467580  No Quote      []   \n",
       "\n",
       "                                                  tokens  \\\n",
       "1231   [>, patty, flipper, malfunctions, >, DEI, hire...   \n",
       "1617   [he, 's, a, mi6, puke, using, a, cia, provided...   \n",
       "1715   [seems, fake, or, he, 's, DEI, hire, or, pfize...   \n",
       "1774   [Checked, ,, this, was, Blizzard, 's, new, DEI...   \n",
       "1808   [all, the, traders, know, everything, is, fake...   \n",
       "...                                                  ...   \n",
       "70771  [Shill, me, why, I, should, vote, for, your, p...   \n",
       "70781  [VPN, hohol, detected, You, 've, got, a, point...   \n",
       "70784  [She, 's, a, DEI, hire, ,, so, no, ., Post, Re...   \n",
       "70795  [Being, a, low, IQ, DEI, hire, with, an, activ...   \n",
       "70801  [Lol, ., Kamala, is, a, DEI, hire, ., Post, Re...   \n",
       "\n",
       "                                             tokenslower  \\\n",
       "1231   [patty, flipper, malfunctions, dei, hire, with...   \n",
       "1617   [he, 's, a, mi6, puke, using, a, cia, provided...   \n",
       "1715   [seems, fake, or, he, 's, dei, hire, or, pfize...   \n",
       "1774   [checked, this, was, blizzard, 's, new, dei, h...   \n",
       "1808   [all, the, traders, know, everything, is, fake...   \n",
       "...                                                  ...   \n",
       "70771  [shill, me, why, i, should, vote, for, your, p...   \n",
       "70781  [vpn, hohol, detected, you, 've, got, a, point...   \n",
       "70784      [she, 's, a, dei, hire, so, no, post, report]   \n",
       "70795  [being, a, low, iq, dei, hire, with, an, activ...   \n",
       "70801      [lol, kamala, is, a, dei, hire, post, report]   \n",
       "\n",
       "                                                  Tokens    CV  \n",
       "1231   [patty, flipper, malfunctions, dei, hire, with...  0.00  \n",
       "1617   [he's, a, mi6, puke, using, a, cia, provided, ...  0.00  \n",
       "1715   [seems, fake, or, he's, dei, hire, or, pfizer,...  0.01  \n",
       "1774   [checked, this, was, blizzard's, new, dei, hir...  0.01  \n",
       "1808   [all, the, traders, know, everything, is, fake...  0.00  \n",
       "...                                                  ...   ...  \n",
       "70771  [shill, me, why, i, should, vote, for, your, p...  0.00  \n",
       "70781  [vpn, hohol, detected, you've, got, a, point, ...  0.00  \n",
       "70784        [she's, a, dei, hire, so, no, post, report]  0.29  \n",
       "70795  [being, a, low, iq, dei, hire, with, an, activ...  0.00  \n",
       "70801      [lol, kamala, is, a, dei, hire, post, report]  0.45  \n",
       "\n",
       "[1551 rows x 11 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_hire = [m for m in target_df['Tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (939) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 939].  Tensor sizes: [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [134], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m tokens \u001b[39min\u001b[39;00m sentences_hire:\n\u001b[0;32m----> 2\u001b[0m     embeddings \u001b[39m=\u001b[39m get_all_word_embeddings(tokens)\n\u001b[1;32m      3\u001b[0m     all_embeddings\u001b[39m.\u001b[39mappend(embeddings)\n",
      "Cell \u001b[0;32mIn [129], line 9\u001b[0m, in \u001b[0;36mget_all_word_embeddings\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# get bert embeddings\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 9\u001b[0m     outputs \u001b[39m=\u001b[39m model(input_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[1;32m     11\u001b[0m \u001b[39m# get embeddings for each word\u001b[39;00m\n\u001b[1;32m     12\u001b[0m embeddings \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlast_hidden_state[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:988\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings, \u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    987\u001b[0m     buffered_token_type_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings\u001b[39m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 988\u001b[0m     buffered_token_type_ids_expanded \u001b[39m=\u001b[39m buffered_token_type_ids\u001b[39m.\u001b[39;49mexpand(batch_size, seq_length)\n\u001b[1;32m    989\u001b[0m     token_type_ids \u001b[39m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    990\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (939) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 939].  Tensor sizes: [1, 512]"
     ]
    }
   ],
   "source": [
    "for tokens in sentences_hire:\n",
    "    embeddings = get_all_word_embeddings(tokens)\n",
    "    all_embeddings.append(embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda3671ff3204f7c08d6fd700d73245b2febe83cbc27407a5dbd57f565cde480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
