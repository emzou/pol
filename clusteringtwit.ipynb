{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial import ConvexHull\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) find optimal clustering \n",
    "2) load into labelstudio, qualitatively get senses\n",
    "3) attribute replies w/ senses \n",
    "4) get the thread content bro... (actually im not sure how big of a deal this is, because idk how many instances are only 1-level replies, though we need this anyways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextinfodict = {\"345\": \"Full 'dei' /pol/ threads, February - August 2024\",\n",
    "\"567embeds\": \"Full 'dei' /pol/ threads, June- October 2024\", \n",
    "\"allembeds\": \"Full threads from /pol/ with 'dei', September 2022 - October 2024\",\n",
    "\"dv_pol_\": \"All of /pol/ in Nov 2019\", \n",
    "\"DEIpol\" : \"Text with 'dei' on /pol/, September 2022 - October 2024\", \n",
    "\"rando2embeds\" : \"Third of randomly shuffled full threads, September 2022- October 2024\", \n",
    "\"28_twtembs\": \"U.S Election Tweets posted August 26-28 2024\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextinfodict = {\"345\": \"Every parent post that contained 'dei', and children comments, from /pol/ between February and August 2024\",\n",
    "\"567embeds\": \"Every parent post that contained 'dei', and children comments, from /pol/ between June and October 2024\", \n",
    "\"allembeds\": \"Every parent post that contained 'dei', and children comments, from /pol/ between September 2022 and October 2024\",\n",
    "\"dv_pol_\": \"Random selection of posts/comments posted on all of /pol in November 2019; collected from Papasavva et al. 2020\", \n",
    "\"DEIpol\" : \"Only posts/comments that contained 'dei', from September 2022 to October 2024\", \n",
    "\"rando2embeds\" : \"A randomly shuffled third of the all parent+ children text corpus\", \n",
    "\"28_twtembs\": \"5.8million tweets related to the US 2024 Elections posted from August 26-28 2024, designated and collected by Balasubramanian et al. 2024\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word_embeddings(parent_folder, contextinfodict, min_clusters=2, max_clusters=6, tsne_perplexity=30):\n",
    "    word_stats = {}\n",
    "    for word_folder in os.listdir(parent_folder):\n",
    "        word_path = os.path.join(parent_folder, word_folder)\n",
    "        if not os.path.isdir(word_path):\n",
    "            continue\n",
    "        context_files = [f for f in os.listdir(word_path) if f.endswith('.csv')]\n",
    "        tsne_fig, axes = plt.subplots(1, len(context_files), figsize=(6 * len(context_files), 6))\n",
    "        if len(context_files) == 1:\n",
    "            axes = [axes]\n",
    "        word_stats[word_folder] = []\n",
    "        for idx, context_file in enumerate(context_files):\n",
    "            context_path = os.path.join(word_path, context_file)\n",
    "            context_name = os.path.splitext(context_file)[0]\n",
    "            data = pd.read_csv(context_path)\n",
    "            if 'Dim1' not in data.columns or 'Dim2' not in data.columns:\n",
    "                continue\n",
    "\n",
    "            inertia_values = []\n",
    "            silhouette_scores = []\n",
    "            db_scores = []\n",
    "            bic_values = []\n",
    "            gap_statistics = []\n",
    "\n",
    "            for k in range(min_clusters, max_clusters + 1):\n",
    "                kmeans = KMeans(n_clusters=k, random_state=123)\n",
    "                clusters = kmeans.fit_predict(data[['Dim1', 'Dim2']])\n",
    "                inertia_values.append(kmeans.inertia_)\n",
    "                if k > 1:\n",
    "                    silhouette_scores.append(silhouette_score(data[['Dim1', 'Dim2']], clusters))\n",
    "                    db_scores.append(davies_bouldin_score(data[['Dim1', 'Dim2']], clusters))\n",
    "                gmm = GaussianMixture(n_components=k, random_state=123)\n",
    "                gmm.fit(data[['Dim1', 'Dim2']])\n",
    "                bic_values.append(gmm.bic(data[['Dim1', 'Dim2']]))\n",
    "                if k > 1:\n",
    "                    reference_inertia = []\n",
    "                    for _ in range(10):\n",
    "                        random_data = np.random.uniform(\n",
    "                            low=data[['Dim1', 'Dim2']].min(),\n",
    "                            high=data[['Dim1', 'Dim2']].max(),\n",
    "                            size=data[['Dim1', 'Dim2']].shape\n",
    "                        )\n",
    "                        random_kmeans = KMeans(n_clusters=k, random_state=123).fit(random_data)\n",
    "                        reference_inertia.append(random_kmeans.inertia_)\n",
    "                    gap = np.log(np.mean(reference_inertia)) - np.log(kmeans.inertia_)\n",
    "                    gap_statistics.append(gap)\n",
    "\n",
    "            optimal_k_silhouette = silhouette_scores.index(max(silhouette_scores)) + min_clusters if silhouette_scores else min_clusters\n",
    "            optimal_k_davies_bouldin = db_scores.index(min(db_scores)) + min_clusters if db_scores else min_clusters\n",
    "            optimal_k_gmm = bic_values.index(min(bic_values)) + min_clusters if bic_values else min_clusters\n",
    "            optimal_k_gap = gap_statistics.index(max(gap_statistics)) + min_clusters if gap_statistics else min_clusters\n",
    "\n",
    "            gap_kmeans = KMeans(n_clusters=optimal_k_gap, random_state=123)\n",
    "            data['gap_cluster'] = gap_kmeans.fit_predict(data[['Dim1', 'Dim2']])\n",
    "            # Add cluster assignments for each method to the DataFrame\n",
    "            data['gap_cluster'] = gap_kmeans.fit_predict(data[['Dim1', 'Dim2']])\n",
    "            data['silhouette_cluster'] = KMeans(n_clusters=optimal_k_silhouette, random_state=123).fit_predict(data[['Dim1', 'Dim2']])\n",
    "            data['davies_bouldin_cluster'] = KMeans(n_clusters=optimal_k_davies_bouldin, random_state=123).fit_predict(data[['Dim1', 'Dim2']])\n",
    "            data['gmm_cluster'] = GaussianMixture(n_components=optimal_k_gmm, random_state=123).fit_predict(data[['Dim1', 'Dim2']])\n",
    "\n",
    "            # Save to CSV\n",
    "            output_csv_path = os.path.join(word_path, f\"{context_name}_clustering_results.csv\")\n",
    "            data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "\n",
    "            ax = axes[idx]\n",
    "            sns.scatterplot(\n",
    "                data=data, x='Dim1', y='Dim2', hue='gap_cluster', palette='icefire', ax=ax, s=50, alpha=1\n",
    "            )\n",
    "\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend(handles=handles, labels=labels, title='gap clusters', fontsize=8)\n",
    "\n",
    "            for method, optimal_k, color, label in [\n",
    "                ('silhouette', optimal_k_silhouette, 'lightgrey', 'Silhouette'),\n",
    "                ('davies_bouldin', optimal_k_davies_bouldin, 'slategray', 'Davies-Bouldin'),\n",
    "                ('gmm', optimal_k_gmm, 'dimgray', 'GMM')\n",
    "            ]:\n",
    "                overlay_kmeans = KMeans(n_clusters=optimal_k, random_state=123)\n",
    "                overlay_clusters = overlay_kmeans.fit_predict(data[['Dim1', 'Dim2']])\n",
    "                for cluster in range(optimal_k):\n",
    "                    cluster_points = data[['Dim1', 'Dim2']][overlay_clusters == cluster].values\n",
    "                    if len(cluster_points) > 2:\n",
    "                        hull = ConvexHull(cluster_points)\n",
    "                        polygon = patches.Polygon(cluster_points[hull.vertices], \n",
    "                                                   edgecolor=color, facecolor=color, \n",
    "                                                   alpha=0.1, label=f\"{label} (k={optimal_k})\", zorder = 1)\n",
    "                        ax.add_patch(polygon)  \n",
    "            description = next((v for k, v in contextinfodict.items() if k in context_name), context_name)\n",
    "            description = next((v for k, v in contextinfodict.items() if k in context_name), context_name)\n",
    "            silhouette_metric = max(silhouette_scores) if silhouette_scores else 'N/A'\n",
    "            davies_bouldin_metric = min(db_scores) if db_scores else 'N/A'\n",
    "            gmm_bic_metric = min(bic_values) if bic_values else 'N/A'\n",
    "            ax.set_title(\n",
    "                f\"{description} | \"\n",
    "                f\"n = {len(data)} \\n \",\n",
    "                fontsize=10, ha='center', va='top'\n",
    "                )\n",
    "            ax.text(\n",
    "                0.5,-0.15,\n",
    "                f\"clustering metrics: Gap = {optimal_k_gap}, Silhouette = {optimal_k_silhouette} (Score: {silhouette_metric if silhouette_metric == 'N/A' else f'{silhouette_metric:.2f}'}),\" \n",
    "                f\"Davies-Bouldin = {optimal_k_davies_bouldin} (Score: {davies_bouldin_metric if davies_bouldin_metric == 'N/A' else f'{davies_bouldin_metric:.2f}'}),\\n \"\n",
    "                f\"GMM = {optimal_k_gmm} (BIC: {gmm_bic_metric if gmm_bic_metric == 'N/A' else f'{gmm_bic_metric:.2f}'})\",\n",
    "                fontsize=8, ha='center', va='top', transform=ax.transAxes\n",
    "                )\n",
    "        tsne_fig.suptitle(f\"tSNE visualization for {word_folder}\", fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(os.path.join(word_path, f\"{word_folder}_clustersv8.png\"))\n",
    "        plt.close(tsne_fig)\n",
    "    return word_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = 'C:\\\\Users\\\\emzou\\\\Desktop\\\\luffy'\n",
    "\n",
    "# Run the function\n",
    "results = process_word_embeddings(\n",
    "    parent_folder=parent_folder,\n",
    "    contextinfodict = contextinfodict,\n",
    "    min_clusters=2,\n",
    "    max_clusters=6,\n",
    "    tsne_perplexity=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = [\n",
    "        patches.Patch(color='blue', alpha=0.2, label='Silhouette'),\n",
    "        patches.Patch(color='red', alpha=0.2, label='Davies-Bouldin'),\n",
    "        patches.Patch(color='yellow', alpha=0.2, label='GMM')\n",
    "        ]\n",
    "        tsne_fig.legend(\n",
    "        handles=handles, loc='upper left', bbox_to_anchor=(0.2, 0.95), \n",
    "        ncol=3, title='other clustering methods', fontsize=8, title_fontsize=10\n",
    "        )\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend(handles=handles, labels=labels, title='gap clusters', loc='upper right', fontsize=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
