{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "import re \n",
    "from lingua import Language, LanguageDetectorBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data\"\n",
    "output_file = 'raw_merged_22_24.txt'\n",
    "content_list = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            content_list.append(content)\n",
    "\n",
    "merged_content = '\\n\\n'.join(content_list)\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as output:\n",
    "    output.write(merged_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_as_string(file_path):\n",
    "    text = Path(file_path).read_text(encoding='utf-8')\n",
    "    return text\n",
    "\n",
    "filepath = 'raw_merged_22_24.txt'\n",
    "text = read_file_as_string(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_by_identifier_and_content(text):\n",
    "    # Updated regex pattern to capture identifier + content after ViewReport\n",
    "    pattern = r'(\\S+\\s*ID:[\\S]+\\s+\\w{3}\\s+\\d{2}\\s+\\w{3}\\s+\\d{4}\\s+\\d{2}:\\d{2}:\\d{2}.*?)\\s+ViewReport(.*?)(?=\\s+\\S+\\s*ID:|\\Z)'\n",
    "\n",
    "    # Find all matches based on the pattern\n",
    "    sections = re.findall(pattern, text, flags=re.DOTALL)\n",
    "\n",
    "    # Return sections as tuples of (identifier, content)\n",
    "    result = [(section[0].strip(), section[1].strip()) for section in sections]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(split_text_by_identifier_and_content(text), columns = ['Identifier', 'Text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_process_replies(df):\n",
    "    df['id'] = df['Identifier'].apply(lambda text: re.findall(r'ID:([^\\s]+)', text)[0] if re.findall(r'ID:([^\\s]+)', text) else None)\n",
    "    df['Date'] = df['Identifier'].apply(lambda text: re.findall(r'ID:\\S+\\s+(\\S+\\s+\\d{2}\\s+\\S+\\s+\\d{4}\\s+\\d{2}:\\d{2}:\\d{2})', text)[0] if re.findall(r'ID:\\S+\\s+(\\S+\\s+\\d{2}\\s+\\S+\\s+\\d{4}\\s+\\d{2}:\\d{2}:\\d{2})', text) else None)\n",
    "    df['Thread No'] = df['Identifier'].apply(lambda text: re.findall(r'No\\.(\\d+)', text)[0] if re.findall(r'No\\.(\\d+)', text) else None)\n",
    "    df['Quoted By'] = df['Text'].apply(lambda text: re.findall(r'quoted by:\\s*>>\\d+', text, flags=re.IGNORECASE))\n",
    "    df['Reply To'] = df['Text'].apply(lambda text: re.findall(r'>>\\d+', text))\n",
    "    \n",
    "    df['Text'] = df['Text'].apply(lambda text: re.sub(r'quoted by:\\s*>>\\d+\\s*', '', text, flags=re.IGNORECASE).strip())\n",
    "    df['Text'] = df['Text'].apply(lambda text: re.sub(r'>>\\d+\\s*', '', text).strip())\n",
    "    df['Text'] = df['Text'].apply(lambda text: re.sub(r'No\\.\\d+\\s*', '', text).strip())\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_and_process_replies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip website links from the text\n",
    "# it means 'image of god' in latin \n",
    "sitepattern = r'(?:https?://|www\\.)\\S+|[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,6}(?:/[^\\s]*)?'\n",
    "df['Text'] = df['Text'].apply(lambda text: re.sub(sitepattern, '', text).strip())\n",
    "# strip 'imago dei' comments from the text\n",
    "df = df[~df['Text'].str.contains('imago', case=False, na=False)]\n",
    "df = df[~df['Text'].str.contains('amplissimus', case=False, na=False)]\n",
    "# strip Post Reply\n",
    "postpattern = r'Post\\nReply'\n",
    "df['Text'] = df['Text'].apply(lambda text: re.sub(postpattern, '', text).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to get rid of this pattern for the millionth time \n",
    "metapattern = r'.{5}(sameocrgoogleiqdbsaucenaotrace).*'\n",
    "df['Text'] = df['Text'].apply(lambda text: re.sub(metapattern, '', text ).strip())\n",
    "# trying to get rid of this pattern for the millionth time \n",
    "metapattern2 = r'.{5}(samegoogleiqdbsaucenaotrace).*'\n",
    "df['Text'] = df['Text'].apply(lambda text: re.sub(metapattern2, '', text ).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LATIN EXTERMINATION!!! \n",
    "# lingua-py (https://github.com/pemistahl/lingua-py)\n",
    "languages = [Language.LATIN, Language.ENGLISH]\n",
    "detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "\n",
    "def latin_exterminator(s):\n",
    "    confidence_value = detector.compute_language_confidence(s, Language.LATIN)\n",
    "    cv = float(f\"{confidence_value:.2f}\") \n",
    "    if cv >= 0.5:\n",
    "        return None\n",
    "    else: \n",
    "        return s\n",
    "\n",
    "#use the latin exterminator\n",
    "df['Text'] = df['Text'].apply(latin_exterminator)\n",
    "df = df[df['Text'].notnull()]\n",
    "\n",
    "# drop duplicates by anon-id (this only refers to the post, not the account)\n",
    "df = df.drop_duplicates(subset = 'id', keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"nov12_dataset_full.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
