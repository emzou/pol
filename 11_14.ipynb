{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd \n",
    "import re \n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"redata\"\n",
    "output_file = 'raw_merged_sep22_jun23.txt'\n",
    "content_list = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            content_list.append(content)\n",
    "\n",
    "merged_content = '\\n\\n'.join(content_list)\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as output:\n",
    "    output.write(merged_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_as_string(file_path):\n",
    "    text = Path(file_path).read_text(encoding='utf-8')\n",
    "    return text\n",
    "\n",
    "filepath = '/Users/emilyzou/Desktop/pol/raw_merged_sep22_jun23.txt'\n",
    "text = read_file_as_string(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_json (input_string): \n",
    "    html = input_string\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    soup = BeautifulSoup(input_string, 'html.parser')\n",
    "    posts_data = []\n",
    "    for post_wrapper in soup.find_all(\"div\", class_=\"post_wrapper\"):\n",
    "        post_data = {\n",
    "            \"post_data\": {\n",
    "                \"author\": post_wrapper.find(\"span\", class_=\"post_author\").text.strip() if post_wrapper.find(\"span\", class_=\"post_author\") else \"\",\n",
    "                \"tripcode\": post_wrapper.find(\"span\", class_=\"post_tripcode\").text.strip() if post_wrapper.find(\"span\", class_=\"post_tripcode\") else \"\",\n",
    "                \"poster_hash\": post_wrapper.find(\"span\", class_=\"poster_hash\").text.strip() if post_wrapper.find(\"span\", class_=\"poster_hash\") else \"\",\n",
    "                \"datetime\": post_wrapper.find(\"time\")[\"datetime\"] if post_wrapper.find(\"time\") else \"\",\n",
    "                \"time_text\": post_wrapper.find(\"time\").text.strip() if post_wrapper.find(\"time\") else \"\",\n",
    "                \"post_id\": post_wrapper.find(\"a\", {\"data-function\": \"quote\"})[\"data-post\"] if post_wrapper.find(\"a\", {\"data-function\": \"quote\"}) else \"\",\n",
    "                \"post_link\": post_wrapper.find(\"a\", {\"data-function\": \"quote\"})[\"href\"] if post_wrapper.find(\"a\", {\"data-function\": \"quote\"}) else \"\"\n",
    "            },\n",
    "            \"controls\": {\n",
    "                \"controls_links\": [\n",
    "                    control.get(\"href\", \"#\") for control in post_wrapper.select(\".post_controls a\")\n",
    "                ]\n",
    "            },\n",
    "            \"backlink_list\": {\n",
    "                \"quoted_by\": [\n",
    "                    backlink[\"data-post\"] for backlink in post_wrapper.select(\".post_backlink\")\n",
    "                ]\n",
    "            },\n",
    "            \"text_content\": {\n",
    "                \"text\": post_wrapper.find(\"div\", class_=\"text\").get_text(separator=\"\\n\").strip() if post_wrapper.find(\"div\", class_=\"text\") else \"\",\n",
    "                \"greentext_links\": [\n",
    "                    link[\"href\"] for link in post_wrapper.find_all(\"a\", class_=\"backlink\") if link\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        posts_data.append(post_data)\n",
    "    json_output = json.dumps(posts_data, indent=4)\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6443\n"
     ]
    }
   ],
   "source": [
    "data = json.loads(return_json(text))\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "da = df[['post_data.poster_hash', \n",
    "        'post_data.datetime', \n",
    "        'post_data.post_id',\n",
    "        'post_data.post_link', \n",
    "        #'backlink_list.quoted_by', \n",
    "        'text_content.text']].rename(columns = \n",
    "        {'post_data.poster_hash': 'poster_ID', \n",
    "        'post_data.datetime': 'date', \n",
    "        'post_data.post_id' :'post_id', \n",
    "        'post_data.post_link': 'post_link', \n",
    "        #'backlink_list.quoted_by': 'quoted_by', \n",
    "        'text_content.text': 'text'\n",
    "         })\n",
    "\n",
    "def threadno_get(url): \n",
    "    thread_number = re.search(r'/thread/(\\d+)', url)\n",
    "    if thread_number:\n",
    "        return thread_number.group(1)\n",
    "    else: \n",
    "        return \"No Thread Number Found... Uh Oh...\"\n",
    "\n",
    "da['Thread_No'] = da['post_link'].apply(threadno_get)\n",
    "da['Reply_To'] = da['text'].apply(lambda text: re.findall(r'>>(\\d+)', text))\n",
    "da['text'] = da['text'].apply(lambda text: re.sub(r'>>\\d+\\s*', '', text).strip())\n",
    "\n",
    "print (len(da['Thread_No']))\n",
    "\n",
    "languages = [Language.LATIN, Language.ENGLISH]\n",
    "detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "\n",
    "def latin_exterminator(s):\n",
    "    confidence_value = detector.compute_language_confidence(s, Language.LATIN)\n",
    "    cv = float(f\"{confidence_value:.2f}\") \n",
    "    if cv >= 0.5:\n",
    "        return None\n",
    "    else: \n",
    "        return s\n",
    "\n",
    "#use the latin exterminator\n",
    "da['text'] = da['text'].apply(latin_exterminator)\n",
    "da = da[da['text'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before duplicate remover, len => 6443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['Imago Dei', \"\"\"Luke 1:28, 1:42\"\"\"] ## if these in the string, delete the whole thing\n",
    "\n",
    "da = da[~da['text'].str.contains('Imago Dei', case=False, na=False)]\n",
    "da = da[~da['text'].str.contains(\"\"\"Luke 1:28, 1:42\"\"\", case=False, na=False)]\n",
    "da = da[~da['text'].str.contains(\"Opus Dei\", case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.drop_duplicates(subset = 'poster_ID', keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after duplicate remover, len => 2535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_no_list = list(set([m for m in da['Thread_No']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2074"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(thread_no_list) => 2074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"thread_jun22_sep23.txt\", \"w\") as file:\n",
    "    for thread in thread_no_list:\n",
    "        file.write(thread + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda3671ff3204f7c08d6fd700d73245b2febe83cbc27407a5dbd57f565cde480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
